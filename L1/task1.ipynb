{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c4a088",
   "metadata": {},
   "source": [
    "TASK 1\n",
    "\n",
    "###### Task 1: Vector and matrix basics (NumPy)\n",
    "###### TODO: Create two vectors (length 3) and compute:\n",
    "###### - dot product\n",
    "###### - L2 norm\n",
    "###### - cosine similarity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc78cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4f826",
   "metadata": {},
   "source": [
    "###### Både python-listnotation och numparray funkar\n",
    "###### Numpyarrayer är möjligtvis effektivare i minnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfefe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product using two numpy arrays 56\n",
      "The dot product using a python list + python list 179\n",
      "The dot product using a python list + numpy array 44\n"
     ]
    }
   ],
   "source": [
    "a = [5, 6, 9]\n",
    "b = [7, 21, 2]\n",
    "\n",
    "vector1= np.array([1,2,3])\n",
    "vector2= np.array([4,8,12])\n",
    "\n",
    "dot_prod = np.dot(vector1,vector2) \n",
    "\n",
    "print(\"The dot product using two numpy arrays\", dot_prod)  \n",
    "print(\"The dot product using a python list + python list\", np.dot(a, b)) \n",
    "print(\"The dot product using a python list + numpy array\", np.dot(a, vector1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273c7b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2-normalisering för vector1 är: 3.7416573867739413\n",
      "L2-normalisering för vector2 är: 14.966629547095765\n"
     ]
    }
   ],
   "source": [
    "l2_norm = np.linalg.norm(vector1)\n",
    "print(\"L2-normalisering för vector1 är:\", l2_norm)\n",
    "\n",
    "l2_norm_vector2 = np.linalg.norm(vector2)\n",
    "print(\"L2-normalisering för vector2 är:\" , l2_norm_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3076734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_v1_v2 = np.dot(vector1, vector2) / (l2_norm * l2_norm_vector2)\n",
    "cos_sim_v1_v2_ALTERATIVE = dot_prod / (l2_norm * l2_norm_vector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ba1b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosinge similarity of vector1 and vector2 is:  1.0\n",
      "The cosinge similarity of vector1 and vector2 is:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The cosinge similarity of vector1 and vector2 is: \", cos_sim_v1_v2)\n",
    "print(\"The cosinge similarity of vector1 and vector2 is: \", cos_sim_v1_v2_ALTERATIVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba703b",
   "metadata": {},
   "source": [
    "###### TODO: Create a 2x3 matrix and multiply it by a length-3 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d615174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of our matrix multiplication is: [31 29]\n"
     ]
    }
   ],
   "source": [
    "matris1 = [[2 , 4, 7], [1, 5, 6]]\n",
    "matrix_multiplication = matris1 @ vector1\n",
    "print(\"Result of our matrix multiplication is:\", matrix_multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74535c4",
   "metadata": {},
   "source": [
    "# Task 2: Eager vs graph execution\n",
    "\n",
    "\n",
    "###### TODO: Write a small function f(x) = x^3 + 2x\n",
    "###### TODO: Implement f(x) in ONE of:\n",
    "###### - PyTorch (eager)\n",
    "###### - TensorFlow with @tf.function (graph)\n",
    "###### - JAX with @jit (graph-like)\n",
    "###### TODO: Print the output and note how execution differs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0798a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613ced5",
   "metadata": {},
   "source": [
    "###### Task 2: Eager vs graph execution\n",
    "###### TODO: Write a small function f(x) = x^3 + 2x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f62ac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vi testar funktionen med 7, svaret är : 357\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "     return x**3 + 2*x\n",
    "\n",
    "print(\"Vi testar funktionen med 7, svaret är :\", f(7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11efdc",
   "metadata": {},
   "source": [
    "###### TODO: Implement f(x) in ONE of:\n",
    "###### - PyTorch (eager) = VÄLJER DEN \n",
    "\n",
    "###### - TensorFlow with @tf.function (graph)\n",
    "###### - JAX with @jit (graph-like)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38c8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(7.0)\n",
    "y = f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2db452",
   "metadata": {},
   "source": [
    "###### I regel är kör PyTorch kod i eager stil (en rad i taget)\n",
    "###### Om man använder torch.compile, så kör den i graph-stil\n",
    "###### jag tror dock att det inte funkar på MPS backend (Mac) och inte har CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b53e6",
   "metadata": {},
   "source": [
    "#### Next note:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b3c2b",
   "metadata": {},
   "source": [
    "###### Med funktionen nedan kan vi undersöka om vi har cuda på vår dator\n",
    "###### Att byta till cuda/mps (alltså grafikkortet), ger oss många fler\n",
    "###### beräkningsenheter => mer effektiv beräkning \n",
    "###### Det här är en av de största anledningarna till PyTorch/TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3ae755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------    Dessa 2 raderska du ha med i en .py fil som vill köra pytorch -------- #\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# ------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fcfd920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version PyTorch was built with: 12.1\n",
      "Device count: 1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version PyTorch was built with:\", torch.version.cuda)\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3726a5",
   "metadata": {},
   "source": [
    "###### TODO: Print the output and note how execution differs-Eager vs graph execution\n",
    "\n",
    "###### Time är ett bibliotek, som låter oss mäta tid\n",
    "###### ofta använder vi det för att jämföra olika kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f13d5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4a44714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution time: 0.034116268157958984 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1. Eager Execution (Standard)\n",
    "x = torch.randn(10000, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Warm up\n",
    "start_time = time.time()\n",
    "_ = f(x)\n",
    "eager_time = time.time() - start_time\n",
    "print(f\"Eager execution time: {eager_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04968a",
   "metadata": {},
   "source": [
    "###### 2. Graph Execution (Compiled)\n",
    "###### torch.compile uses the inductor backend, which doesn't support MPS yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a10ba94",
   "metadata": {},
   "outputs": [
    {
     "ename": "BackendCompilerFailed",
     "evalue": "backend='inductor' raised:\nRuntimeError: Found NVIDIA GeForce MX250 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1446\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1445\u001b[39m     compiler_fn = WrapperBackend(compiler_fn)\n\u001b[32m-> \u001b[39m\u001b[32m1446\u001b[39m compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m _step_logger()(logging.INFO, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py:129\u001b[39m, in \u001b[36mWrapBackendDebug.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     compiled_gm = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\__init__.py:2234\u001b[39m, in \u001b[36m_TorchCompileInductorWrapper.__call__\u001b[39m\u001b[34m(self, model_, inputs_)\u001b[39m\n\u001b[32m   2232\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompile_fx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[32m-> \u001b[39m\u001b[32m2234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1521\u001b[39m, in \u001b[36mcompile_fx\u001b[39m\u001b[34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[39m\n\u001b[32m   1516\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m V.set_fake_mode(fake_mode), torch._guards.tracing(\n\u001b[32m   1517\u001b[39m     tracing_context\n\u001b[32m   1518\u001b[39m ), compiled_autograd.disable(), functorch_config.patch(\n\u001b[32m   1519\u001b[39m     unlift_effect_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1520\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py:72\u001b[39m, in \u001b[36mAotAutograd.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     cg = \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33maot_autograd\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:1071\u001b[39m, in \u001b[36maot_module_simplified\u001b[39m\u001b[34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs)\u001b[39m\n\u001b[32m   1070\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     compiled_fn = \u001b[43mdispatch_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch._dynamo.utils.GmWrapper):\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001b[39;00m\n\u001b[32m   1077\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:1056\u001b[39m, in \u001b[36maot_module_simplified.<locals>.dispatch_and_compile\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd.disable():\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     compiled_fn, _ = \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:522\u001b[39m, in \u001b[36mcreate_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcreate_aot_dispatcher_function\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_env\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:759\u001b[39m, in \u001b[36m_create_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    757\u001b[39m compiler_fn = choose_dispatcher(needs_autograd, aot_config)\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m compiled_fn, fw_metadata = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_dup_fake_script_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn, fw_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py:179\u001b[39m, in \u001b[36maot_dispatch_base\u001b[39m\u001b[34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TracingContext.report_output_strides() \u001b[38;5;28;01mas\u001b[39;00m fwd_output_strides:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     compiled_fw = \u001b[43mcompiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_flat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fakified_out_wrapper.needs_post_compile:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1350\u001b[39m, in \u001b[36mcompile_fx.<locals>.fw_compiler_base\u001b[39m\u001b[34m(model, example_inputs, is_inference)\u001b[39m\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_utils.dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcompile_fx.<locals>.fw_compiler_base\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1350\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fw_compiler_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1421\u001b[39m, in \u001b[36mcompile_fx.<locals>._fw_compiler_base\u001b[39m\u001b[34m(model, example_inputs, is_inference)\u001b[39m\n\u001b[32m   1413\u001b[39m     user_visible_outputs = \u001b[38;5;28mdict\u001b[39m.fromkeys(\n\u001b[32m   1414\u001b[39m         n.name\n\u001b[32m   1415\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m model_outputs[\n\u001b[32m   (...)\u001b[39m\u001b[32m   1418\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, torch.fx.Node)\n\u001b[32m   1419\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_static_input_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_visible_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_visible_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1430\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:475\u001b[39m, in \u001b[36mcompile_fx_inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m stack.enter_context(DebugContext())\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minductor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py:85\u001b[39m, in \u001b[36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     inner_compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:661\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, cudagraphs, static_input_idxs, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, boxed_forward_device_index, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[39m\n\u001b[32m    659\u001b[39m             \u001b[38;5;28minput\u001b[39m._is_inductor_static = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m     compiled_graph = \u001b[43mFxGraphCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfx_graph_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mremote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfx_graph_remote_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py:1334\u001b[39m, in \u001b[36mFxGraphCache.load\u001b[39m\u001b[34m(compile_fx_fn, gm, example_inputs, fx_kwargs, inputs_to_check, local, remote)\u001b[39m\n\u001b[32m   1333\u001b[39m cache_event_time = start_time\n\u001b[32m-> \u001b[39m\u001b[32m1334\u001b[39m compiled_graph = \u001b[43mcompile_fx_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfx_kwargs\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1337\u001b[39m compiled_graph._time_taken_ns = time_ns() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:570\u001b[39m, in \u001b[36m_compile_fx_inner.<locals>.codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, inputs_to_check, fx_kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[33;03mThis function calls fx_codegen_and_compile and also adds some extra metadata to the resulting\u001b[39;00m\n\u001b[32m    568\u001b[39m \u001b[33;03mcompiled fx graph. The metadata is saved to FXGraphCache.\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m compiled_graph = \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfx_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_graph, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;66;03m# We only return a string in aot mode, in which case we don't\u001b[39;00m\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# need to do any post-compilation steps: we just return the string,\u001b[39;00m\n\u001b[32m    574\u001b[39m     \u001b[38;5;66;03m# which is the filename of the compiled code.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:878\u001b[39m, in \u001b[36mfx_codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, cudagraphs, static_input_idxs, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[39m\n\u001b[32m    877\u001b[39m _check_triton_bf16_support(graph)\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m compiled_fn = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_to_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    879\u001b[39m num_bytes, nodes_num_elem, node_runtimes = graph.count_bytes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:1913\u001b[39m, in \u001b[36mGraphLowering.compile_to_fn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1913\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.call\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:1839\u001b[39m, in \u001b[36mGraphLowering.compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1836\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   1837\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGraphLowering.compile_to_module\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mcode_gen\u001b[39m\u001b[33m\"\u001b[39m, fwd_only=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1838\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:1845\u001b[39m, in \u001b[36mGraphLowering._compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodecache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyCodeCache\n\u001b[32m   1844\u001b[39m code, linemap = (\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28mself\u001b[39m.codegen_with_cpp_wrapper() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cpp_wrapper \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m )\n\u001b[32m   1848\u001b[39m GraphLowering.save_output_code(code)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:1780\u001b[39m, in \u001b[36mGraphLowering.codegen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28mself\u001b[39m.init_wrapper_code()\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m \u001b[38;5;28mself\u001b[39m.scheduler = \u001b[43mScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1781\u001b[39m V.debug.draw_orig_fx_graph(\u001b[38;5;28mself\u001b[39m.orig_gm, \u001b[38;5;28mself\u001b[39m.scheduler.nodes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1731\u001b[39m, in \u001b[36mScheduler.__init__\u001b[39m\u001b[34m(self, nodes)\u001b[39m\n\u001b[32m   1730\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mScheduler.__init__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1731\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1749\u001b[39m, in \u001b[36mScheduler._init\u001b[39m\u001b[34m(self, nodes)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28mself\u001b[39m.available_buffer_names = OrderedSet(\n\u001b[32m   1742\u001b[39m     [\n\u001b[32m   1743\u001b[39m         *V.graph.graph_inputs.keys(),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1746\u001b[39m     ]\n\u001b[32m   1747\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m \u001b[38;5;28mself\u001b[39m.nodes = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_scheduler_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28mself\u001b[39m.update_zero_dim_cpu_tensor()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1749\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28mself\u001b[39m.available_buffer_names = OrderedSet(\n\u001b[32m   1742\u001b[39m     [\n\u001b[32m   1743\u001b[39m         *V.graph.graph_inputs.keys(),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1746\u001b[39m     ]\n\u001b[32m   1747\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m \u001b[38;5;28mself\u001b[39m.nodes = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_scheduler_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[32m   1750\u001b[39m \u001b[38;5;28mself\u001b[39m.update_zero_dim_cpu_tensor()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1856\u001b[39m, in \u001b[36mScheduler.create_scheduler_node\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (ir.ComputedBuffer, ir.TemplateBuffer)):\n\u001b[32m-> \u001b[39m\u001b[32m1856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSchedulerNode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, ir.ExternKernel):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:833\u001b[39m, in \u001b[36mSchedulerNode.__init__\u001b[39m\u001b[34m(self, scheduler, node)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._init_from_node(node)\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_attrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:846\u001b[39m, in \u001b[36mSchedulerNode._compute_attrs\u001b[39m\u001b[34m(self, extra_indexing_constraints, recompute_sizes_body_func)\u001b[39m\n\u001b[32m    841\u001b[39m \u001b[38;5;28mself\u001b[39m._sizes, \u001b[38;5;28mself\u001b[39m._body = \u001b[38;5;28mself\u001b[39m.node.simplify_and_reorder(\n\u001b[32m    842\u001b[39m     extra_indexing_constraints=extra_indexing_constraints,\n\u001b[32m    843\u001b[39m     recompute_sizes_body_func=recompute_sizes_body_func,\n\u001b[32m    844\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m846\u001b[39m group_fn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.group_fn\n\u001b[32m    847\u001b[39m \u001b[38;5;28mself\u001b[39m.group = (\u001b[38;5;28mself\u001b[39m.node.get_device(), group_fn(\u001b[38;5;28mself\u001b[39m._sizes))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:3360\u001b[39m, in \u001b[36mScheduler.get_backend\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m   3359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backends:\n\u001b[32m-> \u001b[39m\u001b[32m3360\u001b[39m     \u001b[38;5;28mself\u001b[39m.backends[device] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3361\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backends[device]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:3348\u001b[39m, in \u001b[36mScheduler.create_backend\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m   3344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3345\u001b[39m     device.type == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3346\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (device_props := torch.cuda.get_device_properties(device)).major < \u001b[32m7\u001b[39m\n\u001b[32m   3347\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m3348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   3349\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_props.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_props.major\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_props.minor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# noqa: B950\u001b[39;00m\n\u001b[32m   3350\u001b[39m     )\n\u001b[32m   3351\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_gpu(device.type):\n",
      "\u001b[31mRuntimeError\u001b[39m: Found NVIDIA GeForce MX250 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mBackendCompilerFailed\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# First call triggers the compilation (slower), subsequent calls are fast\u001b[39;00m\n\u001b[32m      4\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m _ = \u001b[43mcompiled_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m graph_time = time.time() - start_time\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGraph execution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:465\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    460\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    461\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    462\u001b[39m )\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    468\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    469\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    470\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1269\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1263\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1264\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1265\u001b[39m             )\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1064\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1062\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:526\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    510\u001b[39m compile_id = CompileId(frame_id, frame_compile_id)\n\u001b[32m    512\u001b[39m signpost_event(\n\u001b[32m    513\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    514\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m_convert_frame_assert._compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m     },\n\u001b[32m    524\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:924\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    922\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:666\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33m_compile.compile_inner\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mentire_frame_compile\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    665\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m CompileTimeInstructionCounter.record():\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_utils_internal.py:87\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     90\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     91\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:699\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    697\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py:1322\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1319\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1320\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:219\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m exit_stack.enter_context(\n\u001b[32m    216\u001b[39m     torch.fx._symbolic_trace._maybe_revert_all_patches()\n\u001b[32m    217\u001b[39m )\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:634\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    636\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2796\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2795\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2796\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:983\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    982\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    984\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:895\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2987\u001b[39m, in \u001b[36mInstructionTranslator.RETURN_VALUE\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2986\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mRETURN_VALUE\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m2987\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2972\u001b[39m, in \u001b[36mInstructionTranslator._return\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2967\u001b[39m _step_logger()(\n\u001b[32m   2968\u001b[39m     logging.INFO,\n\u001b[32m   2969\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.f_code.co_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst.opname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2970\u001b[39m )\n\u001b[32m   2971\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m triggered compile\u001b[39m\u001b[33m\"\u001b[39m, inst.opname)\n\u001b[32m-> \u001b[39m\u001b[32m2972\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2973\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2975\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreturn_value\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   2976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2978\u001b[39m return_inst = (\n\u001b[32m   2979\u001b[39m     create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2980\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inst.opname == \u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2981\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_CONST\u001b[39m\u001b[33m\"\u001b[39m, argval=inst.argval)\n\u001b[32m   2982\u001b[39m )\n\u001b[32m   2983\u001b[39m \u001b[38;5;28mself\u001b[39m.output.add_output_instructions([return_inst])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1117\u001b[39m, in \u001b[36mOutputGraph.compile_subgraph\u001b[39m\u001b[34m(self, tx, partial_convert, reason)\u001b[39m\n\u001b[32m   1114\u001b[39m append_prefix_insts()\n\u001b[32m   1115\u001b[39m \u001b[38;5;66;03m# optimization to generate better code in a common case\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28mself\u001b[39m.add_output_instructions(\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1118\u001b[39m     + [create_instruction(\u001b[33m\"\u001b[39m\u001b[33mUNPACK_SEQUENCE\u001b[39m\u001b[33m\"\u001b[39m, arg=\u001b[38;5;28mlen\u001b[39m(stack_values))]\n\u001b[32m   1119\u001b[39m )\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# restore all the live local vars\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28mself\u001b[39m.add_output_instructions(\n\u001b[32m   1122\u001b[39m     [PyCodegen(tx).create_store(var) \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(restore_vars)]\n\u001b[32m   1123\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1369\u001b[39m, in \u001b[36mOutputGraph.compile_and_call_fx_graph\u001b[39m\u001b[34m(self, tx, rv, root)\u001b[39m\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracing_context.fake_mode = backend_fake_mode\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.restore_global_state():\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m     compiled_fn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_graph_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LazyGraphModule\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, _LazyGraphModule) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(compiled_fn, \u001b[33m\"\u001b[39m\u001b[33m__self__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), _LazyGraphModule)\n\u001b[32m   1375\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m compiled_fn.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m_lazy_forward\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1379\u001b[39m     \u001b[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001b[39;00m\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# optimize a _LazyGraphModule.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1416\u001b[39m, in \u001b[36mOutputGraph.call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_user_compiler\u001b[39m(\u001b[38;5;28mself\u001b[39m, gm: fx.GraphModule) -> CompiledFn:\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   1414\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mbackend_compile\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1415\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1465\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1464\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BackendCompilerFailed(\u001b[38;5;28mself\u001b[39m.compiler_fn, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1467\u001b[39m signpost_event(\n\u001b[32m   1468\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1469\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1475\u001b[39m     },\n\u001b[32m   1476\u001b[39m )\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[31mBackendCompilerFailed\u001b[39m: backend='inductor' raised:\nRuntimeError: Found NVIDIA GeForce MX250 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "# This 'traces' the function and optimizes the kernels\n",
    "compiled_f = torch.compile(f)\n",
    "# First call triggers the compilation (slower), subsequent calls are fast\n",
    "start_time = time.time()\n",
    "_ = compiled_f(x)\n",
    "graph_time = time.time() - start_time\n",
    "print(f\"Graph execution time: {graph_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da6b42",
   "metadata": {},
   "source": [
    "Task 3\n",
    "\n",
    "\n",
    "###### Task 3: Framework comparison in code\n",
    "###### TODO: Using scikit-learn, load the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeb7e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data =load_iris()\n",
    "#print(data)\n",
    "\n",
    "X = data[\"data\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec44a7",
   "metadata": {},
   "source": [
    "###### TODO: Train a LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85c0de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tasmi\\mlops\\ml_ramverk\\ML-Frameworks\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)\n",
    "print(model.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687abbb2",
   "metadata": {},
   "source": [
    "###### TODO: Train a tiny MLP (MLPClassifier) on the same data\n",
    "###### TODO: Compare accuracy and write 3-5 comments in code about:\n",
    "###### - speed\n",
    "###### - API ergonomics\n",
    "###### - when you would pick each approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54130354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! You now have a first hands-on view of ML frameworks.\n",
      "Keep these snippets for future comparison in later lessons.\n"
     ]
    }
   ],
   "source": [
    "print(\"Done! You now have a first hands-on view of ML frameworks.\")\n",
    "print(\"Keep these snippets for future comparison in later lessons.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Frameworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
